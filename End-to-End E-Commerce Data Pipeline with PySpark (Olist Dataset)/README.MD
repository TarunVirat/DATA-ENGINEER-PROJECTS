
---

## 🛠️ Tech Stack
- **Apache Spark (PySpark)** – distributed ETL & analytics  
- **HDFS (Hadoop Distributed File System)** – storage  
- **Jupyter Notebooks** – development & visualization  
- **Parquet** – optimized columnar storage  
- **Python (Pandas, Matplotlib, Seaborn)** – EDA & visualizations  

---

## 👨‍💻 Author
**Tarun Peela**  
📍 Gainesville, FL | Data Engineer | Data Scientist  
🔗 [LinkedIn](https://www.linkedin.com/in/tarunpeela)  
📧 tarun.peela@example.com  

---

## 🚀 How to Run
1. Clone this repo & download the [Kaggle dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce).  
2. Upload the CSVs to HDFS path `/user/<username>/olist/`.  
3. Launch Jupyter Notebook inside your Spark cluster (GCP, AWS EMR, or local).  
4. Run notebooks in order (`Module 1 → Module 5`).  
5. Processed Parquet files will be available under `/user/<username>/olist/processed/`.

---

## 📈 Example Analysis
- Customer Retention (first vs last order per unique customer).  
- Seller Performance by review score & revenue.  
- Payment method popularity & installment analysis.  
- Geographical spread of orders across Brazil.  

---

## 📌 References
- [Kaggle – Olist Brazilian E-Commerce Dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)  
- Olist Official Documentation  
