
---

## ğŸ› ï¸ Tech Stack
- **Apache Spark (PySpark)** â€“ distributed ETL & analytics  
- **HDFS (Hadoop Distributed File System)** â€“ storage  
- **Jupyter Notebooks** â€“ development & visualization  
- **Parquet** â€“ optimized columnar storage  
- **Python (Pandas, Matplotlib, Seaborn)** â€“ EDA & visualizations  

---

## ğŸ‘¨â€ğŸ’» Author
**Tarun Peela**  
ğŸ“ Gainesville, FL | Data Engineer | Data Scientist  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/tarunpeela)  
ğŸ“§ tarun.peela@example.com  

---

## ğŸš€ How to Run
1. Clone this repo & download the [Kaggle dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce).  
2. Upload the CSVs to HDFS path `/user/<username>/olist/`.  
3. Launch Jupyter Notebook inside your Spark cluster (GCP, AWS EMR, or local).  
4. Run notebooks in order (`Module 1 â†’ Module 5`).  
5. Processed Parquet files will be available under `/user/<username>/olist/processed/`.

---

## ğŸ“ˆ Example Analysis
- Customer Retention (first vs last order per unique customer).  
- Seller Performance by review score & revenue.  
- Payment method popularity & installment analysis.  
- Geographical spread of orders across Brazil.  

---

## ğŸ“Œ References
- [Kaggle â€“ Olist Brazilian E-Commerce Dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce)  
- Olist Official Documentation  
