# ğŸ›’ Brazilian E-Commerce Data Pipeline with Azure & Databricks  

This project builds an **end-to-end big data pipeline** using the **Olist Brazilian E-Commerce dataset**.  
The goal is to design, transform, and analyze large-scale e-commerce data using modern cloud tools, enabling actionable business insights.  

---

## ğŸ“Š Architecture  

![Architecture Diagram](Architecture%20Diagram.png)

**Flow:**  
1. **Data Sources**: Olist datasets (customers, orders, payments, reviews, products, sellers, geolocation).  
2. **Ingestion**: Data loaded into **Azure Data Lake Storage (ADLS Gen2)** via **Azure Data Factory**.  
3. **Transformation**: Processing and enrichment with **Azure Databricks** (PySpark).  
4. **Storage**: Curated datasets stored back in ADLS Gen2.  
5. **Analytics & Visualization**: Data loaded into **Azure Synapse** and visualized in **Power BI/Tableau/Fabric**.  
6. **External Enrichment**: Additional tables from **MongoDB** integrated for business context.  

---

## ğŸ“‚ Project Structure  

```
Brazilian-Ecommerce-BigData/
â”‚â”€â”€ Data/                         # Olist dataset CSV files
â”‚â”€â”€ Codes/                        # PySpark / SQL scripts
â”‚â”€â”€ DataIngestionToDB.ipynb       # Notebook for ingestion
â”‚â”€â”€ ForEachInput.json             # Config for ADF pipeline
â”‚â”€â”€ sql code/                     # SQL transformation scripts
â”‚â”€â”€ notes.txt                     # Handwritten study notes
â”‚â”€â”€ Architecture Diagram.png      # Final pipeline diagram
â”‚â”€â”€ Architecture Diagram.excalidraw # Editable source diagram
â”‚â”€â”€ README.md
```

---

## ğŸ“š Dataset  

We use the [Olist Brazilian E-Commerce dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce).  
It contains multiple linked tables:  

- `olist_customers_dataset.csv` â†’ Customer details  
- `olist_orders_dataset.csv` â†’ Orders & timestamps  
- `olist_order_items_dataset.csv` â†’ Products in each order  
- `olist_order_payments_dataset.csv` â†’ Payment methods & values  
- `olist_order_reviews_dataset.csv` â†’ Customer reviews & ratings  
- `olist_products_dataset.csv` â†’ Product catalog  
- `olist_sellers_dataset.csv` â†’ Seller information  
- `olist_geolocation_dataset.csv` â†’ Customer & seller locations  
- `product_category_name_translation.csv` â†’ English mapping for product categories  

---

## âš™ï¸ Tech Stack  

- **Data Lake**: Azure Data Lake Storage Gen2  
- **Orchestration**: Azure Data Factory  
- **Processing**: Azure Databricks (PySpark)  
- **Data Warehouse**: Azure Synapse Analytics  
- **NoSQL Enrichment**: MongoDB  
- **Visualization**: Power BI, Tableau, Microsoft Fabric  

---

## ğŸš€ How to Run  

1. Clone this repo  
   ```bash
   git clone https://github.com/YOURUSERNAME/Brazilian-Ecommerce-BigData.git
   cd Brazilian-Ecommerce-BigData
   ```
2. Upload the `Data/` folder to your ADLS Gen2 container.  
3. Deploy the **ADF pipeline** using `ForEachInput.json`.  
4. Open `DataIngestionToDB.ipynb` in **Databricks** and execute transformations.  
5. Run SQL scripts inside **Synapse** to build reporting tables.  
6. Connect Power BI/Tableau/Fabric to Synapse for dashboards.  

---

## ğŸ“ˆ Sample Insights  

- Top-selling product categories and seasonality  
- Payment method trends (credit card, boleto, voucher, etc.)  
- Customer satisfaction by seller/product (review scores)  
- Delivery performance vs promised SLA  
- Revenue growth by state & region  

---

## ğŸ‘¨â€ğŸ’» Author  

**Tarun Peela**  
ğŸ“ Tampa, FL | Data Engineer / Data Scientist  
ğŸ“§ tarunpeela0@gmail.com  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/tarunpeela)  
ğŸ”— [GitHub](https://github.com/TarunVirat)  

---
